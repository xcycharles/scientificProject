{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import yahoo_fin.stock_info as si\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import scipy.optimize as spop\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "# https://www.youtube.com/watch?v=jvZ0vuC9oJk&list=PLE4a3phdCOauXaK3f1QMI_fEIqEYTsH9I&index=3\n",
    "# https://www.machinelearningplus.com/time-series/augmented-dickey-fuller-test/\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pykalman import KalmanFilter\n",
    "from scipy import poly1d\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    df['fft price'] = 0.0\n",
    "    df['net_return'] = 0.0\n",
    "    df['long signal'] = 0\n",
    "    df['kf price'] = 0.0\n",
    "    \n",
    "    signal = 0\n",
    "    global delta\n",
    "    global theta\n",
    "    global amplitude\n",
    "    global freq\n",
    "    global sample1\n",
    "    global sample2\n",
    "\n",
    "    # do FFT stock price perdiction on every day\n",
    "    for i in range(window+2,len(df)):  ## remember to change it back to full len(df) ## need +2 as it's min for fft transform\n",
    "\n",
    "        sample1 = df[i-window:i].copy()\n",
    "\n",
    "        # do FFT stock price perdiction on every day\n",
    "\n",
    "        delta = np.array([])\n",
    "        theta = np.array([])\n",
    "        amplitude = np.array([])\n",
    "        freq = np.array([])\n",
    "        delta = sample1['price'].diff()\n",
    "        delta = delta[1:]\n",
    "        sp = np.fft.fft(delta.values) # fft must be done without and NaN\n",
    "        theta = np.arctan(sp.imag/sp.real) # phase in polar form\n",
    "        amplitude = np.sqrt(sp.real**2 + sp.imag**2)/(window/2)# we only care about positive absolute amplitude, therefore 1/2\n",
    "        freq = np.fft.fftfreq(sp.size) # cycles per sample spacing\n",
    "        std_values = []\n",
    "        rmse_values = []\n",
    "        # loop thru and try diff std filter thresholds\n",
    "        for j in np.linspace(0,4,20): # 100 steps, infer step size\n",
    "            std_values.append(j)\n",
    "            rmse_values.append(fft_std_filter(j))\n",
    "        #print(rmse_values)\n",
    "        idx = np.array(rmse_values).argmin()\n",
    "        minSTD = std_values[idx]\n",
    "        #print('minSTD is '+str(minSTD))\n",
    "        minRMSE = rmse_values[idx]\n",
    "        #print('minRMSE is '+str(minRMSE))\n",
    "        fft_std_filter(minSTD)\n",
    "        df['fft price'][i] = regression[-1]\n",
    "\n",
    "\n",
    "\n",
    "        # Use the observed values of the price to get a rolling mean\n",
    "        state_means, _ = kf.filter(df['fft price'][:i]) # ignore cov so repalce with _\n",
    "        df['kf price'][i] = state_means[-1]\n",
    "        \n",
    "        sample2 = df[i-window:i].copy()\n",
    "\n",
    "        X = sm.add_constant(sample2['kf price'])\n",
    "        results = sm.OLS(sample2['price'],sample2['kf price']).fit()\n",
    "        beta = results.params['kf price']\n",
    "        #print(f'beta is {beta}')\n",
    "        sample2['cointegration'] = sample2['price'] - beta * sample2['kf price'] \n",
    "        # this is the noise should be mean reverting, spread is scaled by beta rather than simple difference\n",
    "        result = adfuller(sample2['cointegration'], autolag='AIC')\n",
    "        result2 = coint(beta*sample2['kf price'],sample2['price'])\n",
    "        \n",
    "        if i == window+2: # starting point\n",
    "            old_signal = 0 # the long short signal\n",
    "        if result[0] > result[4]['10%'] or result2[0] > result2[2][2]: # nothing happens\n",
    "            signal = 0\n",
    "            df['net_return'].iloc[i,:] = 0\n",
    "        elif result[0] < result[4]['10%'] and result2[0] < result2[2][2] \\\n",
    "        and (sample2['cointegration'][-1]-sample2['cointegration'].mean())/sample2['cointegration'].std() > -999:\n",
    "            # trigger trading signal when test statistic is more negative for Augmanted Dickey Fuller unit roo test\n",
    "            # based on time series diff beta stationarity. More negative means more likey to reject unit root exists which make nonstatioanry\n",
    "            # from dickey and fuller unit root test, more negative is better\n",
    "            # trigger trading signal when test statistic is more negative for Engle-Granger test (based on residual stationarity)\n",
    "            # trigger signal when cointegration spread zscore above 1 std\n",
    "        \n",
    "            signal = np.sign(df['price'][i] - beta * df['kf price'][i]) # if - then long the stock, as undervalued\n",
    "            df['long signal'].iloc[i,:] = -signal\n",
    "            gross_return = -signal*df['return'][i]\n",
    "            fees = fee*abs(signal - old_signal)\n",
    "            net_return = gross_return - fees\n",
    "            df['net_return'].iloc[i,:] = net_return\n",
    "        old_signal = signal\n",
    "\n",
    "    df['open long'] = df['long signal'].diff()\n",
    "    annual_return_positive = str(round(np.power(df[\"net_return\"].cumsum()[-1]*100,360/len(df[window+2:])),2))+'%'\n",
    "    annual_sharpe_positive = round(np.power(df[\"net_return\"][window:].mean()/df[\"net_return\"][window:].std(),360/len(df[window+2:])),2)\n",
    "    annual_return_negative = str(round(df[\"net_return\"].cumsum()[-1]*100,2))+'%'\n",
    "    annual_sharpe_negative = round((df[\"net_return\"][window:].mean()/df[\"net_return\"][window:].std()),2)\n",
    "    max_drawdown = str(round(df[\"net_return\"].cumsum().min()*100,2))+'%'\n",
    "    number_of_trades = int(np.power(np.count_nonzero(df[\"open long\"]!=0),360/len(df[window+2:])))\n",
    "\n",
    "    if df[\"net_return\"].cumsum()[-1] > 0:\n",
    "        return stock,window,annual_return_positive,annual_sharpe_positive,max_drawdown,number_of_trades\n",
    "    elif df[\"net_return\"].cumsum()[-1] == 0:\n",
    "        return stock,window,annual_return_negative,0,max_drawdown,number_of_trades\n",
    "    elif df[\"net_return\"].cumsum()[-1] < 0:\n",
    "        return stock,window,annual_return_negative,annual_sharpe_negative,max_drawdown,number_of_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_std_filter(std_value):\n",
    "    # for the variables can be used outside function\n",
    "    global regressionDelta\n",
    "    global regression\n",
    "    regressionDelta = 0\n",
    "    regression = 0\n",
    "    #Getting dominant values based on std_value\n",
    "    meanAmp = amplitude.mean()\n",
    "    stdAmp = amplitude.std()\n",
    "    dominantAmp = list(filter(lambda x : x > (std_value*stdAmp + meanAmp),amplitude))\n",
    "    dominantTheta = theta\n",
    "    #Calculating Regression Delta\n",
    "    for n in range(len(dominantAmp)):\n",
    "        shift = dominantTheta[n]\n",
    "        regressionDelta += dominantAmp[n] * np.cos(n * np.array(range(window)) + shift) # adding up till len(sample1)\n",
    "    #Converting Delta Time to Time at start value of real data\n",
    "    startValue = sample1['price'][0]\n",
    "    regression = startValue + np.cumsum(regressionDelta)\n",
    "    #Calculating RMSE\n",
    "    rmse = np.sqrt(np.mean((sample1['price'].values - regression)**2))\n",
    "    #if np.isnan(rmse) or len(regression)==1:\n",
    "    if np.isnan(rmse):\n",
    "        rmse = 10000000000000\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a Kalman filter\n",
    "kf = KalmanFilter(observation_matrices = [1], # this tells us the next measurement we should expect given the predicted next state\n",
    "                  # or this can be random walk if modeling a fairly stable system so next move would be the same 1*\n",
    "                  # observation matrix will dot with transition matrix\n",
    "                  observation_covariance=1, # assume price has variance 1 under R.W model (hard to know)\n",
    "                  # also this represents the error of the guesses\n",
    "                  initial_state_mean = 0, # guess 0 for 1d\n",
    "                  initial_state_covariance = 1, # assume price move as our model says, 1 for identity matrix. error for guess\n",
    "                  transition_matrices = [1], # how state evolves (identity matrix if R.W)\n",
    "                  transition_covariance=.01)# this is the kalman gain or err term for transition matrix: \n",
    "                  # (Err_state)/(Err_state+Err_measure)\n",
    "                  # important to keep track this as new measurements come in, also hard to know\n",
    "                  # bigger this value, more overfitting\n",
    "                  # close to 1 means stock price is accurate - weigh more on recent event\n",
    "                  # close to 0 means stock price is not accurate - weigh more on historical event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#specifying parameters\n",
    "start = '2019-01-01'\n",
    "end = '2021-01-01'\n",
    "fee = 0.001\n",
    "dow_list = si.tickers_dow()\n",
    "result = pd.DataFrame([],columns=['stock','window','annual return','annual sharpe','max drawdown','number of trades'])\n",
    "\n",
    "\n",
    "#for i in ['AAPL','TSLA','JPM']:\n",
    "for i in dow_list:\n",
    "    for j in np.linspace(start=30,stop=200,num=3):\n",
    "        window = int(j)\n",
    "        stock = i\n",
    "        #retrieving data\n",
    "        df = pd.DataFrame()\n",
    "        returns = pd.DataFrame()\n",
    "        prices = yf.download(i, start, end)\n",
    "        df['price'] = prices['Adj Close']\n",
    "        #df['return'] = prices['Adj Close'].pct_change().shift(-1)\n",
    "        df['return'] = np.log(prices['Adj Close']).diff().shift(-1)\n",
    "        # important! need to match today's price (or signal) with tomorrow's return in the same df row for backtesting\n",
    "        df = df[:-1]\n",
    "        result = result.append(pd.Series(data=main(),index=result.columns),ignore_index=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',100)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
